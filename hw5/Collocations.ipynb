{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用经过人工分词后的北京大学《人民日报》标注语料库，实现搭配自动发现程序\n",
    "要求每种方法列出 前10个搭配的 **词对** 及其**得分**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import chardet  \n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "\n",
    "def paths(path):\n",
    "    path_collection=[]\n",
    "    for dirpath,dirnames,filenames in os.walk(path):\n",
    "        for file in filenames:\n",
    "            fullpath=os.path.join(dirpath,file)\n",
    "            path_collection.append(fullpath)\n",
    "    return path_collection\n",
    "\n",
    "def get_tokens(path):\n",
    "    words = [] #文档中出现的所有词\n",
    "    for i,file in enumerate(paths(path)):\n",
    "    # for i,file in enumerate([\"corpus/01060108.txt\"]):\n",
    "        with open(file) as somefile:\n",
    "            for line in somefile:\n",
    "                linestr = line.strip().decode(\"gbk\")\n",
    "                for w in linestr.split('  '):\n",
    "                    tmp = w.split('/')[0]\n",
    "                    if len(tmp)>1 and tmp[0] == '[':\n",
    "                        tmp = tmp[1:]\n",
    "                    words.append(tmp)\n",
    "    return words\n",
    "\n",
    "\n",
    "separator = [u'。',u'？',u'！',u'：',u'；',u'?',u'!',u':',u';',u'，',u',',u'——',u'、',u'（',u'）']\n",
    "def split_sentence(path_list):\n",
    "    sentences = [] #文档中的所有句子\n",
    "    for i,file in enumerate(path_list):\n",
    "        with open(file) as somefile:\n",
    "            for line in somefile:\n",
    "                linestr = line.strip().decode(\"gbk\")\n",
    "                line_list = linestr.split('  ')\n",
    "                sentence = []\n",
    "                for w in line_list:\n",
    "                    tmp = w.split('/')[0]\n",
    "                    if len(tmp)>1 and tmp[0] == '[':\n",
    "                        tmp = tmp[1:]\n",
    "                    if tmp in separator:\n",
    "                        if len(sentence) > 1:\n",
    "                            sentences.append(sentence)\n",
    "                        sentence = []\n",
    "                    else:\n",
    "                        sentence.append(tmp)\n",
    "                if line_list[-1] not in separator and len(sentence) > 1:\n",
    "                    sentences.append(sentence)\n",
    "    return sentences\n",
    "\n",
    "def formatF(number):\n",
    "    return \"%.6f\" % np.log10(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus_path = \"corpus/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文档数： 3148\n",
      "句子数： 139300\n",
      "词数： 1120721\n"
     ]
    }
   ],
   "source": [
    "corpus_files = paths(corpus_path)\n",
    "sentences = split_sentence(corpus_files)\n",
    "tokens = get_tokens(corpus_path)\n",
    "\n",
    "total_files = len(corpus_files)\n",
    "total_sentences = len(sentences)\n",
    "total_words = len(tokens)\n",
    "print \"文档数：\",total_files\n",
    "print \"句子数：\",total_sentences\n",
    "print \"词数：\",total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateBigram(sentence):\n",
    "    word_list = sentence.split(' ')\n",
    "    bigram_list = []\n",
    "    pre_word = word_list[0]\n",
    "    for w in word_list[1:]:\n",
    "        bigram_list.append(pre_word + \" \" + w)\n",
    "        pre_word = w \n",
    "    return bigram_list\n",
    "\n",
    "class NGram(object):\n",
    "    def __init__(self, n):\n",
    "        # n is the order of n-gram language model\n",
    "        self.n = n\n",
    "        self.unigram = {}\n",
    "        self.bigram = {}\n",
    "\n",
    "    # scan a sentence, extract the ngram and update their\n",
    "    # frequence.\n",
    "    #\n",
    "    # @param    sentence    list{str}\n",
    "    # @return   none\n",
    "    def scan(self, sentences):\n",
    "        # file your code here\n",
    "        for sentence in sentences:\n",
    "            self.ngram(sentence)\n",
    "            \n",
    "    # caluclate the ngram of the words\n",
    "    #\n",
    "    # @param    words       list{str}\n",
    "    # @return   none\n",
    "    def ngram(self, words):\n",
    "        # unigram\n",
    "        if self.n == 1:\n",
    "            for word in words:\n",
    "                if word not in self.unigram:\n",
    "                    self.unigram[word] = 1\n",
    "                else:\n",
    "                    self.unigram[word] = self.unigram[word] + 1\n",
    "\n",
    "        # bigram\n",
    "        if self.n == 2:\n",
    "            pre_word = words[0]\n",
    "            for w in words[1:]:\n",
    "                stri = pre_word + \" \" + w\n",
    "                if stri not in self.bigram:\n",
    "                    self.bigram[stri] = 1\n",
    "                else:\n",
    "                    self.bigram[stri] = self.bigram[stri] + 1\n",
    "                pre_word = w \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 频率方法 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# uni = NGram(1)\n",
    "bi1 = NGram(2)\n",
    "# uni.scan(sentences)\n",
    "bi1.scan(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted_bi = sorted(bi1.bigram.items(),key=lambda x:x[1],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "” 的 970\n",
      "的 一 844\n",
      "的 “ 843\n",
      "新 的 734\n",
      "这 一 645\n",
      "电 （ 574\n",
      "这 是 569\n",
      "的 发展 537\n",
      "（ 记者 530\n",
      "一 种 529\n"
     ]
    }
   ],
   "source": [
    "for b in sorted_bi[:10]:\n",
    "    print b[0],b[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyltp import Segmentor  \n",
    "from pyltp import Postagger  \n",
    "from pyltp import NamedEntityRecognizer\n",
    "\n",
    "LTP_DATA_DIR = '../ltp_data'  # ltp模型目录的路径\n",
    "cws_model_path = os.path.join(LTP_DATA_DIR, 'cws.model')  # 分词模型路径，模型名称为`cws.model`\n",
    "pos_model_path = os.path.join(LTP_DATA_DIR, 'pos.model')\n",
    "ner_model_path = os.path.join(LTP_DATA_DIR, 'ner.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "segmentor = Segmentor()  \n",
    "segmentor.load(cws_model_path)  # 加载模型\n",
    "postagger = Postagger()  \n",
    "postagger.load(pos_model_path)  # 加载模型\n",
    "recognizer = NamedEntityRecognizer()  \n",
    "recognizer.load(ner_model_path)  #加载模型  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "segmentor.release()  #释放模型  \n",
    "# postagger.release()  #释放模型  \n",
    "recognizer.release()  #释放模型  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_rule = ['a n','n n'] # 是否考虑加上nd，nh，ni，nl，ns，nt，nz\n",
    "n_set = ['nz','n']\n",
    "filter_rule = raw_rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_bigram(bigram_dict):\n",
    "    bigram_dict_cp = deepcopy(bigram_dict)\n",
    "    for k,v in bigram_dict_cp.items():\n",
    "        bi_list = k.encode('utf-8').split(' ')\n",
    "        postags = list(postagger.postag(bi_list))\n",
    "        if (postags[0] == 'a' or postags[0] in n_set) and postags[1] in n_set:\n",
    "            pass\n",
    "        else:\n",
    "            bigram_dict_cp.pop(k)\n",
    "    return bigram_dict_cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filtered_bigram = filter_bigram(bi1.bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted_filtered_bigram = sorted(filtered_bigram.items(),key=lambda x:x[1],reverse=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "领导 干部 252\n",
      "讯 记者 225\n",
      "电 记者 219\n",
      "金融 危机 180\n",
      "人民 群众 139\n",
      "社会主义 市场经济 120\n",
      "人民 检察院 120\n",
      "两岸 关系 115\n",
      "多 人 113\n",
      "金融 机构 95\n"
     ]
    }
   ],
   "source": [
    "for i in sorted_filtered_bigram[:10]:\n",
    "    print i[0],i[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 均值-方差方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "window_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Mean_Variance(object):\n",
    "    def __init__(self):\n",
    "        self.win_bigram = {}\n",
    "        self.mean_deviation = {}\n",
    "    \n",
    "    def generate_win_bigram(self, sentences, window_size=3):\n",
    "        for word_list in sentences:\n",
    "            bigram_list = []\n",
    "            for i,w in enumerate(word_list):\n",
    "                if i < window_size:\n",
    "                    first_word = [word_list[j] for j in range(i)] # in the window\n",
    "                    distance = [j for j in range(1,i+1)]\n",
    "                else:\n",
    "                    first_word = [word_list[j] for j in range(i-window_size,i)] # in the window\n",
    "                    distance = [j for j in range(window_size,0,-1)]\n",
    "                second_word = w\n",
    "                for k,f_w in enumerate(first_word):\n",
    "                    b = f_w + \" \" + w\n",
    "                    if not self.win_bigram.has_key(b):\n",
    "                        self.win_bigram[b] = {}\n",
    "                        self.win_bigram[b]['dist'] = [distance[k]]\n",
    "                    else:\n",
    "                        self.win_bigram[b]['dist'].append(distance[k])\n",
    "                        \n",
    "    def calc_mean_deviation(self):\n",
    "        for k,v in self.win_bigram.items():\n",
    "            dist_list = v['dist']\n",
    "            if len(dist_list) < 10:\n",
    "                self.win_bigram.pop(k)\n",
    "            else:\n",
    "                mean = 1.0*sum(dist_list)/len(dist_list)\n",
    "                variance = 1.0*sum([(dist-mean)**2 for dist in dist_list])/(len(dist_list)-1)\n",
    "                deviation = 1.0*variance**0.5\n",
    "                self.win_bigram[k]['mean'] = mean\n",
    "                self.win_bigram[k]['deviation'] = deviation\n",
    "                \n",
    "    def rank(self):\n",
    "        deviation = {}\n",
    "        for k,v in self.win_bigram.items():\n",
    "            if v['mean'] > 1:\n",
    "                deviation[k] = v['deviation']\n",
    "        return sorted(deviation.items(),key=lambda x:x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mv = Mean_Variance()\n",
    "mv.generate_win_bigram(sentences)\n",
    "mv.calc_mean_deviation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = mv.rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "口 航道 0.0 2.0 12\n",
      "记者 林昌 0.0 2.0 11\n",
      "气象 预报 0.0 2.0 33\n",
      "联合国 小组 0.0 3.0 11\n",
      "记者 西平 0.0 2.0 13\n",
      "之 》 0.0 2.0 30\n",
      "已 家 0.0 3.0 20\n",
      "泽民 说 0.0 2.0 25\n",
      "新华社 ８日 0.0 3.0 26\n",
      "２４日 （ 0.0 2.0 17\n"
     ]
    }
   ],
   "source": [
    "bi2 = mv.win_bigram\n",
    "for i in result[:10]:\n",
    "    print i[0],i[1],bi2[i[0]]['mean'],len(bi2[i[0]]['dist']) # w1w2 s d count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 假设检验方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uni3 = NGram(1)\n",
    "uni3.scan(sentences)\n",
    "bi3 = NGram(2)\n",
    "bi3.scan(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class t_Test():\n",
    "    def __init__(self,unigram,bigram):\n",
    "        self.unigram = unigram\n",
    "        self.bigram = bigram\n",
    "    \n",
    "    def calc_word_prob(self,word):\n",
    "        count = self.unigram[word] if self.unigram.has_key(word) else 0\n",
    "        return 1.0*count/len(self.bigram)\n",
    "\n",
    "    def calc_mu(self,bigram):\n",
    "        bi_list = bigram.split(' ')\n",
    "        first_prob = self.calc_word_prob(bi_list[0])\n",
    "        second_prob = self.calc_word_prob(bi_list[1])\n",
    "        return first_prob*second_prob\n",
    "\n",
    "    def calc_mean_x(self,bigram):\n",
    "        count = self.bigram[bigram] if self.bigram.has_key(bigram) else 0\n",
    "        return 1.0*count/len(self.bigram)\n",
    "\n",
    "    def calc_t(self,bigram):\n",
    "        mean_x = self.calc_mean_x(bigram)\n",
    "        mu = self.calc_mu(bigram)\n",
    "        N = len(self.bigram)\n",
    "        variance = mean_x\n",
    "        return (mean_x-mu)/(variance/N)**0.5\n",
    "\n",
    "    def t_test(self,bigram):\n",
    "        if self.calc_t(bigram) > 2.576:# significant level = 0.005\n",
    "            return True\n",
    "        return False # fail to reject the null hypothesis\n",
    "    \n",
    "    def rank(self):\n",
    "        rank = {}\n",
    "        for bigram,v in self.bigram.items():\n",
    "            rank[bigram] = self.calc_t(bigram)\n",
    "        return sorted(rank.items(),key=lambda x:x[1],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t_test = t_Test(uni3.unigram,bi3.bigram)\n",
    "result = t_test.rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "这 一 23.06023 3196 7253 645\n",
      "一 种 22.31461 7253 849 529\n",
      "两 国 22.09021 1952 806 496\n",
      "本报 讯 21.41862 1467 700 464\n",
      "江 泽民 21.0858 602 451 446\n",
      "北京 １月 20.89613 1364 1781 449\n",
      "一 年 20.77873 7253 2516 521\n",
      "这 是 20.48581 3196 9819 569\n",
      "据 新华社 20.1484 1008 1175 412\n",
      "年 来 19.63223 2516 1618 406\n"
     ]
    }
   ],
   "source": [
    "for i in result[:10]:\n",
    "    bi_list = i[0].split(' ')\n",
    "    t = round(i[1], 5)\n",
    "    print i[0],t,uni3.unigram[bi_list[0]],uni3.unigram[bi_list[1]],bi3.bigram[i[0]] # w1w2 t c1 c2 c12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stopword = []\n",
    "with open('./stopword.txt') as f:\n",
    "    for w in f:\n",
    "        stopword.append(w.strip().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stopword_bi = {}\n",
    "for k,v in bi3.bigram.items():\n",
    "    bi_list = k.split(' ')\n",
    "    if (bi_list[0] not in stopword) and (bi_list[1] not in stopword):\n",
    "        stopword_bi[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_test2 = t_Test(uni3.unigram,stopword_bi)\n",
    "result2 = t_test2.rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "两 国 21.84635 1952 806 496\n",
      "本报 讯 21.25405 1467 700 464\n",
      "江 泽民 21.04142 602 451 446\n",
      "北京 １月 20.50037 1364 1781 449\n",
      "附 图片 17.07914 294 369 293\n",
      "新华社 北京 16.34178 1175 1364 286\n",
      "新华社 记者 15.54849 1175 2129 271\n",
      "本报 记者 15.51512 1467 2129 277\n",
      "领导 干部 15.47787 1131 926 252\n",
      "改革 开放 14.7841 1280 355 224\n"
     ]
    }
   ],
   "source": [
    "for i in result2[:10]:\n",
    "    bi_list = i[0].split(' ')\n",
    "    t = round(i[1], 5)\n",
    "    print i[0],t,uni3.unigram[bi_list[0]],uni3.unigram[bi_list[1]],bi3.bigram[i[0]] # w1w2 t c1 c2 c12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 点对互信息方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Mutual_Information():\n",
    "    def __init__(self,unigram,bigram):\n",
    "        self.unigram = unigram\n",
    "        self.bigram = bigram\n",
    "        \n",
    "    def calc_bigram_prob(self,bigram):\n",
    "        count = self.bigram[bigram] if self.bigram.has_key(bigram) else 0\n",
    "        return 1.0*count/len(self.bigram)\n",
    "    \n",
    "    def calc_unigram_prob(self,unigram):\n",
    "        count = self.unigram[unigram] if self.unigram.has_key(unigram) else 0\n",
    "        return 1.0*count/len(self.unigram)\n",
    "    \n",
    "    def calc_I(self,bigram):\n",
    "        bi_list = bigram.split(' ')\n",
    "        first_w = self.calc_unigram_prob(bi_list[0])\n",
    "        second_w = self.calc_unigram_prob(bi_list[1])\n",
    "        bi_prob = self.calc_bigram_prob(bigram)\n",
    "        return np.log2(bi_prob/(first_w*second_w))\n",
    "        \n",
    "    def rank(self):\n",
    "        rank = {}\n",
    "        for bigram,frequency in self.bigram.items():\n",
    "            if frequency > 2:\n",
    "                rank[bigram] = self.calc_I(bigram)\n",
    "#             rank[bigram] = self.bigram[bigram]*self.calc_I(bigram)\n",
    "        return sorted(rank.items(),key=lambda x:x[1],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uni4 = NGram(1)\n",
    "uni4.scan(sentences)\n",
    "bi4 = NGram(2)\n",
    "bi4.scan(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mi = Mutual_Information(uni4.unigram,bi4.bigram)\n",
    "result = mi.rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "丹参 滴丸 11.280967 3 3 3\n",
      "胡图族 叛乱者 11.280967 3 3 3\n",
      "波分 复用 11.280967 3 3 3\n",
      "货仓式 自选商场 11.280967 3 3 3\n",
      "管理课 课长 11.280967 3 3 3\n",
      "孔雀 开屏 11.280967 3 3 3\n",
      "诸葛 仓麟 11.280967 3 3 3\n",
      "上虞 风机厂 11.280967 3 3 3\n",
      "宫内 节育器 11.280967 3 3 3\n",
      "± ％ 11.280967 3 3 3\n"
     ]
    }
   ],
   "source": [
    "for res in result[:10]:\n",
    "    bi_list = res[0].split(' ')\n",
    "    I = round(res[1],6)\n",
    "    print res[0],I,uni4.unigram[bi_list[0]],uni4.unigram[bi_list[1]],bi4.bigram[res[0]]#w1w2 I c1 c2 c12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mi2 = Mutual_Information(uni4.unigram,stopword_bi)\n",
    "result2 = mi2.rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "管理课 课长 12.512658 3 3 3\n",
      "孔雀 开屏 12.512658 3 3 3\n",
      "胡图族 叛乱者 12.512658 3 3 3\n",
      "波分 复用 12.512658 3 3 3\n",
      "丹参 滴丸 12.512658 3 3 3\n",
      "诸葛 仓麟 12.512658 3 3 3\n",
      "上虞 风机厂 12.512658 3 3 3\n",
      "文传 电讯社 12.512658 3 3 3\n",
      "草浆 书写纸 12.512658 3 3 3\n",
      "货仓式 自选商场 12.512658 3 3 3\n"
     ]
    }
   ],
   "source": [
    "for res in result2[:10]:\n",
    "    bi_list = res[0].split(' ')\n",
    "    I = round(res[1],6)\n",
    "    print res[0],I,uni4.unigram[bi_list[0]],uni4.unigram[bi_list[1]],bi4.bigram[res[0]]#w1w2 I c1 c2 c12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
